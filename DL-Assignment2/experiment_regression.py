"""
Experimental analysis 1: Regression task
"""

import torch

from data_plotting import PlotGeneration
from mlp import MLP, mse_loss

# Initialization
num_features, num_mid_neurons, num_outputs = 2, 20, 5
num_training_instances, num_validation_instances = 2000, 500
learning_rate = 0.01

# Training and validation instances generated from normal distribution
x_training = torch.randn(num_training_instances, num_features)
y_training = torch.randn(num_training_instances, num_outputs)

x_validation = torch.randn(num_validation_instances, num_features)
y_validation = torch.randn(num_validation_instances, num_outputs)


def get_training_validation_loss(model):
    """
    :param model: An MLP model
    :return: training and validation loss per epoch generated by globally defined training and validation instances
    """
    num_epoch = 100
    training_loss, validation_loss = [], []

    for _ in range(num_epoch):
        model.clear_grad_and_cache()

        # Training
        y_hat = model.forward(x_training)
        L, dLdy_hat = mse_loss(y_training, y_hat)
        model.backward(dLdy_hat)
        model.update_weight(learning_rate)
        training_loss.append(L)

        # Validation
        y_hat = model.forward(x_validation)
        L, dLdy_hat = mse_loss(y_validation, y_hat)
        validation_loss.append(L)

    return training_loss, validation_loss


# Initialize plotting data and labels
data = []
labels = []

# -------------------------------------------
# identity at output and relu at hidden layer
net1 = MLP(
    linear_1_in_features=num_features,
    linear_1_out_features=num_mid_neurons,
    g_function1='relu',
    linear_2_in_features=num_mid_neurons,
    linear_2_out_features=num_outputs,
    g_function2='identity'
)

# Getting training and validation losses from net1
data.extend(get_training_validation_loss(net1))
labels.extend([f"Training error (relu & identity)", "Validation error (relu & identity)"])

# ----------------------------------------------
# identity at output and sigmoid at hidden layer
net2 = MLP(
    linear_1_in_features=num_features,
    linear_1_out_features=num_mid_neurons,
    g_function1='sigmoid',
    linear_2_in_features=num_mid_neurons,
    linear_2_out_features=num_outputs,
    g_function2='identity'
)

# Getting training and validation losses from net2
data.extend(get_training_validation_loss(net2))
labels.extend(["Training error (sigmoid & identity)", "Validation error (sigmoid & identity)"])

# ----------------------------------
# Plot the accumulated plotting data
PlotGeneration.line_plotting(data, labels=labels)
